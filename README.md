Member-QA: Natural Language Question Answering API
This project is a small question-answering service that can understand natural-language questions and respond with answers inferred from the Member Messages API provided in the challenge.
The API parses a user‚Äôs question, searches through member messages, extracts relevant information, and returns a clean JSON answer.

The service is implemented using FastAPI, deployed on Render, and publicly accessible.

üöÄ Live API
Base URL:
https://member-qa-w3bt.onrender.com
Endpoints
1. Health Check (GET /)
Returns a simple message confirming the service is running.
2. Ask a Question (POST /ask)
Send a natural-language question and receive an inferred answer.
Example request:
{
  "question": "When is Layla planning her trip to London?"
}

How It Works
1. NLP Parsing
A lightweight natural-language parser identifies question type:
‚Äúwhen‚Äù questions ‚Üí date extraction
‚Äúhow many‚Äù questions ‚Üí quantity extraction
fallback ‚Üí return matched message text

2. Message Indexing
On startup, the API fetches all member messages from:
GET https://november7-730026606190.europe-west1.run.app/messages
Messages are indexed locally for:
keyword matching
simple semantic ranking
fast retrieval

3. Answer Extraction
Depending on the parsed question type, the API pulls out:
dates (for ‚Äúwhen‚Äù)
numeric quantities (for ‚Äúhow many‚Äù)
or returns the raw message for descriptive questions

üõ† Running Locally
Prerequisites
Python 3.10+
pip / venv

Install & Run
pip install -r requirements.txt
uvicorn app.main:app --reload
Open your browser at:
http://localhost:8000/docs

Deployment
The API is deployed on Render Web Services using a Dockerfile.
Render automatically detects the service, exposes port 8080, and runs the FastAPI app.

Bonus Section
Bonus 1 ‚Äî Design Notes (Alternatives I Considered)
I evaluated a few different approaches before settling on this solution:
‚úîÔ∏è 1. Full LLM-based QA
Use an LLM (GPT, Llama) to analyze messages and answer questions.
Pros: Very flexible and accurate.
Cons: Expensive, requires API keys, adds latency.
‚úîÔ∏è 2. Embedding-based semantic search
Generate embeddings for each message (e.g., using Sentence-BERT).
Pros: Great for fuzzy matching.
Cons: Extra infrastructure and model hosting.
‚úîÔ∏è 3. Rule-based + keyword matching (Chosen Approach)
Simple, fast, reliable for structured messages.
Matches keywords from the parsed question and applies extraction rules.
This approach was chosen because it's:
lightweight
deterministic
easy to evaluate
deploys quickly

Bonus 2 ‚Äî Data Insights (Anomalies Noticed)
While exploring member messages, I noticed a few inconsistencies:
Some users mention events multiple times with slightly different details (e.g., trip dates differ across messages)
Names sometimes appear with typos or nicknames, causing fuzzy matching challenges
A few messages don‚Äôt match any known user format
Some messages contain multiple pieces of information, requiring careful extraction
These small inconsistencies influenced the design of the parser and extraction logic.

